from nltk.tokenize import word_tokenize
data = "I pledge to be a data scientist one day"
tokenized_text=word_tokenize(data)
print(tokenized_text)
print(type(tokenized_text))